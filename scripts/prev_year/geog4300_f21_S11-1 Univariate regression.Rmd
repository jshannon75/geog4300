---
title: "Geog6300: Univariate regression"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r setup}
library(tidyverse)
library(sf)
```


Here's our garden data from class lecture
```{r}
med.age<-c(43, 21, 25, 42, 56, 59)
garden<-c(99, 65, 79, 75, 87, 81)
data<-data.frame(cbind(med.age, garden))
```

Now we can create a linear model. The actual model doesn't tell you much, but a summary of it does.
```{r}
lm(garden~med.age, data=data) 
model<-lm(garden~med.age, data=data)
summary(model)
```

You can also plot this model. The abline function plots a regression line created by the model.
```{r}
plot(garden~med.age, data=data)
abline(model) 
```

Let's do a more complex model: pollen data. Does yearly mean temperature predict the levels of pollen from birch trees (Betula)? We will load the data and then make it spatial using the st_as_sf function in the sf package.

```{r}
Midwest_Pollen_Data<-read_csv("data/Midwest_Pollen_Data.csv")

pollen_data_sf<-st_as_sf(Midwest_Pollen_Data,coords=c(x="longitud",y="latitude"),crs=4326)
```

Let's look at the distribution of these variables first.
```{r}
hist(pollen_data_sf$Betula)
ggplot(pollen_data_sf,aes(sample=Betula))+
  stat_qq()+stat_qq_line()

hist(pollen_data_sf$tmeanyr)
ggplot(pollen_data_sf,aes(sample=tmeanyr))+
  stat_qq()+stat_qq_line()

ggplot(pollen_data_sf,aes(y=Betula,x=tmeanyr))+
  geom_point()
```

We can use tmap to visualize these points.

```{r}
library(tmap)
tmap_mode("view")
tm_shape(pollen_data_sf) +
  tm_dots("Betula",size=.2)

tm_shape(pollen_data_sf) +
  tm_dots("tmeanyr",size=.2)
```

Now let's create a model.
```{r}
model<-lm(Betula~tmeanyr,data=pollen_data_sf)
summary(model)
```

We can plot out the model.
```{r}
plot(Betula~tmeanyr,data=pollen_data_sf)
abline(model)
```

##There's several diagnostics that can be used for regression.

R comes with some diagnostic plots baked in. To see them, just plot the model. There are four screens: 

1) The first is the values predicted by the model vs. the residuals. It shouldn't show a pattern.

2) The second is a QQ plot for residuals. These should appear normal.

3) The third should also appear random, it's similar to graph 1.

4) The last shows Cook's distance for outliers (See below). It identifies observations with the greatest "leverage" on the model by their row number. They will be near or past the dotted line thresholds.

```{r}
plot(model)
```


Here's a more detailed walkthrough:

*Normality of residuals: Plot/test the residuals. The "residuals" function pulls residuals from the model.
```{r}
pollen_data_sf$residuals<-residuals(model) #Pull the residuals from the model
ggplot(pollen_data_sf,aes(sample=residuals))+
  stat_qq()+stat_qq_line()
shapiro.test(pollen_data_sf$residuals)
```

Map the residuals using tmap
```{r}
tm_shape(pollen_data_sf) +
  tm_dots("residuals",size=.2)
```

*Heteroskedasticity: We can use the Breusch-Pagan test in the lmtest package. The null hypothesis is that the data is uniform, NOT heteroskedastic.
```{r}
library(lmtest)
bptest(model)
```

*Outliers: We'll use Cook's Distance to assess outliers This is adapted from: http://r-statistics.co/Outlier-Treatment-With-R.html See also https://onlinecourses.science.psu.edu/stat501/node/340 and http://www.statisticshowto.com/cooks-distance/.

In th example below, we plot the Cooke's distance for each observation, which shows the leverage it has in the model as a whole. We then add a cutoff line that shows values four times greater than the mean. Lastly, we add labels that give the row number of each identified outlier.

```{r}
cooks_dist<-cooks.distance(model)

plot(cooks_dist, pch="*", cex=2, main="Influential Obs by Cooks distance")
abline(h = 4*mean(cooks_dist, na.rm=T), col="red") 
text(x=1:length(cooks_dist)+1, y=cooks_dist, labels=ifelse(cooks_dist>4*mean(cooks_dist, na.rm=T),names(cooks_dist),""), col="red")  
```

We can go even further. Let's join these distances back to the dataset. We can add a "dummy variable" using if_else highlighting just those observations above that cutoff line.

```{r}
cooks_d<-data.frame(cooks_dist)
cutoff<-mean(cooks_dist)*4

pollen_data_sf<-pollen_data_sf %>%
  bind_cols(cooks_d) %>%
  mutate(outlier=if_else(cooks_dist>cutoff,"1","0")) 
```

Where do those outliers fit in the overall distribution?

```{r}
ggplot(pollen_data_sf,aes(y=Betula,x=tmeanyr,color=outlier))+
  geom_point()
```

Where are these outliers?
```{r}
tm_shape(pollen_data_sf) +
  tm_dots("outlier",size=0.2)
```

Let's run a model without the outliers.
```{r}
pollen_data_sf1<-pollen_data_sf %>%
  filter(outlier==0)
model_rev<-lm(Betula~tmeanyr,data=pollen_data_sf1)
summary(model_rev)

plot(Betula~tmeanyr,data=pollen_data_sf1)
abline(model_rev)
```

##You try it!
Run a model for one other tree species and either temperature or precipitation. Check the diagnostics and interpret your results.

